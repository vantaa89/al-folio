<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Flow Model | Seojune Lee</title> <meta name="author" content="Seojune Lee"> <meta name="description" content="Flow model에 대한 설명"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700%7CRoboto+Slab:100,300,400,500,700%7CMaterial+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https:/vantaa89.github.io//blog/2022/Flow/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Seojune </span>Lee</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Flow Model</h1> <p class="post-meta">December 16, 2022</p> <p class="post-tags"> <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a>   ·   <a href="/blog/tag/deep-learning"> <i class="fas fa-hashtag fa-sm"></i> deep-learning</a>   <a href="/blog/tag/mathdnn"> <i class="fas fa-hashtag fa-sm"></i> MathDNN</a>   </p> </header> <article class="post-content"> <blockquote> <p>Erneset Ryu 교수님의 2022학년도 2학기 &lt;심층신경망의 수학적 기초&gt; 과목을 듣고 필자가 요약해 정리한 글입니다.</p> </blockquote> <p><strong>Flow model</strong>은 GAN(Generative Adversarial Network)이나 VAE(Variational Autoencoder)와 같은 생성 모델의 하나이다. 두 네트워크가 서로 경쟁하며 생성을 한다는 식으로 비교적 쉽게 이해할 수 있는 GAN과, (적어도 구현할 때) 표면적으로는 어느 정도 와닿는 VAE와 달리 Flow model은 그 수학적 기반을 어느 정도 제대로 이해해야 구현을 할 수 있는 것 같다. 이 때문에 필자도 공부를 해보려다가도 엄두를 못 내고 있었는데, 이번 학기에 &lt;심층신경망의 수학적 기초&gt;를 들으면서 Flow model이 나와서 공부할 기회가 있었다. 수업을 들으면서 배운 내용을 간단하게 정리해보겠다.</p> <h1 id="flow-model이란">Flow Model이란</h1> <p>먼저 Flow model이 무엇인지, 어떤 방법을 사용하는지부터 간단하게 짚고 넘어가보자.</p> <p>Flow model은 <strong>probabilistic generative model</strong>의 하나이다. 주어진 데이터셋 \(X_1, X_2, \cdots, X_N\)이 있다고 하자. 여기서, “나올 수 있는 데이터들의 집합”이라는 것이 있고, 더 나아가서 나올 수 있는 데이터들의 확률분포가 있다고 생각을 해보자. 즉, \(X_1, X_2, \cdots, X_N\)는 \(p_{true}\)라는 확률분포로부터 샘플링을 한 것이 된다.</p> \[X_1, X_2, \cdots, X_N \sim p_{true}\] <p>Flow model과 같은 probabilistic generative model의 목표는 이 확률분포 \(p_{true}\)를 모사하는 것이다. 새로운 샘플 \(X\sim p_{\theta}\)를 만들 수 있도록 하는 새로운 확률분포 \(p_{\theta}\)를 적당히 매개화하여 나타내는 것이 목표가 된다.</p> <p>이러한 공통의 목표를 GAN, VAE, 그리고 Flow model은 다음과 같이 다른 방식으로 수행한다.</p> <p align="center" style="color:gray"> <img src="https://lilianweng.github.io/posts/2018-10-13-flow-models/three-generative-models.png" width="80%"> <br> GAN, VAE, 그리고 Flow Model의 비교 (출처: https://lilianweng.github.io/posts/2018-10-13-flow-models/) </p> <p>공통적으로, 세 모델은 모두 입력 데이터 \(X\) 를 <strong>잠재공간(latent space)</strong>상의 벡터 \(Z\) 와 대응시키는 식으로 동작한다. 이떄 잠재공간이란 일종의 차원축소라고도 볼 수 있는데, VAE의 경우를 보면 decoder는 \(Z\)만을 보고도 원래의 \(X\)와 유사한 \(X'\)을 복원해낸다. 이 말은 \(Z\)에 \(X\)에 담겨있는 정보(feature)들이 대부분 담겨있다는 뜻으로도 생각할 수 있을 것이다.</p> <p>눈에 띄는 것은 VAE와 Flow model의 차이이다. VAE에서 encoder와 decoder가 각각 분포를 나타내었고, 두 네트워크가 별개의 가중치를 가졌던 것과 달리(<a href="/blog/2022/VAE/">VAE 포스팅 참고</a>) flow에서는</p> <ol> <li> <p>입력 데이터를 latent space로 보내는, encoder역할을 하는 것이 조건부 확률분포가 아닌 함수 \(f\) 이다. 즉, 하나의 \(X\) 에 대해 \(z\) 가 유일하게, deterministic하게 결정된다.</p> </li> <li> <p>\(f\)는 가역(invertible)이다. 즉, latent vector로부터 데이터를 샘플링하기 위해 별개의 네트워크를 사용할 필요가 없다!</p> </li> <li> <p>VAE에서는 log likelihood 대신 이를 근사하는 ELBO(또는 VLB)를 최대화하였다면, Flow model에서는 log likelihood 그 자체를 최대화한다.</p> </li> </ol> <p>그렇다면 몇 가지 의문점이 생긴다.</p> <ul> <li>잠재벡터 \(Z\)는 왜 필요한 것일까?</li> <li>기존의 컨볼루션, linear layer, ReLU등으로 구성된 신경망은 역변환이 불가능한데, \(f\)를 어떻게 invertible하게 만들 수 있을까?</li> <li>인코더와 디코더를 거친 후 reconstruction loss를 구하면 되는 Autoencoder와 달리, flow model에서는 \(f^{-1}\circ f(X)=X\)가 된다. 그러면 트레이닝은 어떻게 시켜야 할까?</li> </ul> <p>Flow model이 등장한 모티베이션과 그 이론적 배경들을 살펴보면서, 위의 의문점들을 하나씩 해결해보자.</p> <h1 id="maximum-likelihood-estimation">Maximum Likelihood Estimation</h1> <p>앞서 언급했듯이, flow model을 훈련하는 목표는 <strong>maximum likelihood estimation(MLE, 최우도추정)</strong> 을 수행하는 것이다. 분포 \(p_\theta(x)\)에서 나온 표본 \(X_1, X_2, \cdots, X_n\)이 있을 때, 우도(가능도, likelihood)는</p> \[p_\theta(X_1) p_\theta(X_2)\cdots p_\theta(X_n)\] <p>으로 정의된다. 이를 최대화하는 분포 \(p_\theta\)를, 다시 말해 이 분포를 결정하는 매개변수 \(\theta\)를 찾는 것이 바로 최우도추정이다. 이 우도라는 것은 무슨 의미를 가지는 것일까? 앞서 말했듯이, 우리가 flow model을 훈련시키는 목적은 데이터 \(X_1, X_2, \cdots, X_n\)에 내재되어 있는 구조를 파악하는 것이다. 이는 \(p_{true}\)에서 나온 것이므로 이를 근사하는 \(p_{\theta}\)를 구하는 것이 우리의 목표이다.</p> <p>만약 \(p_{\theta}\)가 실제 분포 \(p_{true}\)와 너무 다르다면, \(p_{\theta}\)는 어떤 데이터 \(X_i\)에 대해서 “이런 데이터는 나올 수 없어”라면서 매우 작은 값을 부여할 수도 있을 것이다. 그러면 우도가 매우 작아지게 된다. 따라서 우도가 클수록, 우리의 모델 \(p_{\theta}\)가 실제 분포 \(p_{true}\)에 근접해지는 것이다.</p> <p>그렇다면 각각의 \(X_i\)에 대해서만 \(p_\theta\)값을 크게 하면 되지 않나 하는 생각을 할 수 있을 것이다. 하지만 \(p_{\theta}\)는 확률밀도함수이기 때문에,</p> \[\int p_{\theta}(x) dx = 1\] <p>이라는 기본적인 성질을 만족해야 한다. 즉, \(p_{\theta}\)가 부여할 수 있는 값의 “총량”은 제한되어 있으니, 샘플링된 데이터를 보고 함수값을 잘 배분해서 \(p_{true}\)와 비슷해지도록 하는 것이다.</p> <p>한편, 우도</p> \[p_\theta(X_1) p_\theta(X_2)\cdots p_\theta(X_n)\] <p>는 곱 형태로 되어 있기 떄문에 최대화를 하기가 불편하다. 경사하강법 등을 사용해서 최대화를 수행하려면 식을 미분해야 하는데, 곱 형태로 된 식은 미분이 어렵기 떄문이다. 따라서 로그를 씌워서 <strong>log-likelihood</strong></p> \[\sum_{i=1}^N \log{p_{\theta}(X_i)}\] <p>를 최대화해주게 된다.</p> <h1 id="p_theta의-표현">\(p_{\theta}\)의 표현</h1> <p>그러면 이제 “데이터를 받았을 때, \(p_{\theta}\)에서 \(X_i\)가 나올 확률$$을 neural network를 사용해서 나타내주면 된다. 간단하게 생각하면 이런 방법이 있을 것이다.</p> <blockquote> <p>데이터 X를 입력으로 넣으면 \(p_{\theta}(X)\)를 출력으로 내보내는 신경망</p> </blockquote> <p>그런데 이 방법에는 문제점이 있다. 먼저 정규화(normalization)을 시켜줄 수가 없게 된다. 만약 \(p_{\theta}\)가 이산확률분포였다면, 마지막 계층에 softmax를 한번 씌워주기만 하면 전부 더해서 1이 되도록 강제할 수 있다. 하지만 연속확률분포에서 (1) X를 마구 넣어서 각 X에 대해 \(p_{\theta}(X)\)의 함수값을 구하고 (2) 구분구적법과 같은 방법을 사용해서 적분을 하고 (3) 각각의 함수값을 \(\int p_{\theta}(x)dx\)로 나눠서 정규화하는 것은 굉장히 어려운 작업이다. 따라서 우리는 다른 방법을 써준다. 입력 데이터 \(X\)를 정규분포와 같이 간단한 분포 상의 한 점으로 대응시키는 것이다.</p> <blockquote> <p>데이터 X를 입력으로 넣으면, 이를 간단한 분포 \(p_Z\)상의 \(Z= f_{\theta}(X) \sim p_Z\) 로 대응시키는 신경망</p> </blockquote> <p>이렇게 하면, \(p_{\theta}(x)\)는 자연스럽게 \(p_{\theta}(x)=p_Z(z)= p_Z(f_{\theta}(x))\)로 구할 수가 있게 된다.</p> <p>이는 change of variables formula</p> \[p_{\theta}(X) = \left\vert\frac{\partial z}{\partial x}\right\vert p_{Z}(f_{\theta}(x))\] <p>와 같이 계산된다. 여기서 \(\left\vert\frac{\partial z}{\partial x}\right\vert = \left\vert\frac{\partial f_{\theta}}{\partial x}(x)\right\vert\) 는 Jacobian 행렬의 행렬식(determinant)의 절대값으로, 일종의 부피 변환비같은 역할을 한다.</p> <p>이제 이것을 log likelihood 식에 대입하면 우리의 training objective는 다음과 같다.</p> \[\text{maximize}_{\theta \in \Theta} \sum_{i=1}^N \log{p_{\theta}(X_i)} = \text{maximize}_{\theta \in \Theta} \sum_{i=1}^N \log{p_{Z}(f_{\theta}(X_i))} + \log{\left\vert\frac{\partial f_\theta}{\partial x}(X_i)\right\vert}\] <p>SGD나 Adam같은 optimizer로 위의 최적화를 수행하기만 하면 flow를 훈련시킬 수 있게 되는 것이다. 그런데,</p> \[\log{p_{Z}(f_{\theta}(X_i))} + \log{\left\vert\frac{\partial f_\theta}{\partial x}(X_i)\right\vert}\] <p>의 기울기를 구하고, 샘플링을 통해 새로운 데이터를 얻어내려면 몇 가지 요구사항이 필요하다.</p> <ul> <li>먼저, \(f_{\theta}\)와 \(\nabla_{\theta}f_{\theta}\)를 쉽게 계산할 수 있어야 한다.</li> <li>식에 \(\frac{\partial f_\theta}{\partial x}\)가 나오기 때문에 \(f_\theta\)는 (\(x\)에 대해)미분가능해야 할 것이다.</li> <li>여기에 \(\nabla_{\theta}\)를 씌워서 값을 얻을 수 있어야 하므로,\(\nabla_{\theta}\left\vert\frac{\partial f_\theta}{\partial x}\right\vert\)도 쉽게 계산이 가능해야 한다.</li> <li>마지막으로, sampling을 하기 위해서는 \(f_{\theta}\)가 가역(invertible)이어야 한다. <ul> <li>부연설명을 하자면, 여기서 sampling이란 우리가 근사한 분포 \(p_{\theta}\)로부터 새로운 데이터를 얻어내는 것을 말한다. 이는 \(Z\sim p_Z\)를 하나 샘플링 한 후 \(f^{-1}_\theta(Z)\)를 구함으로써 가능하다. \(f_{\theta}\)가 가역이어야 하는 이유이다.</li> </ul> </li> </ul> <h2 id="flow의-합성">Flow의 합성</h2> <p>기존의 MLP(다층 퍼셉트론)나 CNN(컨볼루션 신경망)에서 층을 여러 개 쌓아서 네트워크의 표현력을 증가시켰듯이, flow에서도 비슷하게 flow를 여러 층으로 쌓아 합성함수를 구성하듯이 표현력을 증가시킬 수 있다. 단순히</p> \[x \mapsto f_1 \mapsto f_2 \mapsto \cdots \mapsto f_n \mapsto z\] <p>와 같이 여러 함수들을 거쳐서 \(x\)가 간단한 분포 \(p_Z\)를 따르는 확률변수로 변환되는 것이다. 이 경우 체인 룰을 사용해서</p> \[\left\vert \frac{\partial f_{\theta}}{\partial x}\right\vert = \left\vert \frac{\partial f_n}{\partial f_{n-1}}\frac{\partial f_{n-1}}{\partial f_{n-2}}\cdots \frac{\partial f_2}{\partial f_1}\frac{\partial f_1}{\partial x}\right\vert\] \[= \left\vert \frac{\partial f_n}{\partial f_{n-1}}\right\vert\left\vert\frac{\partial f_{n-1}}{\partial f_{n-2}}\right\vert\cdots \left\vert\frac{\partial f_2}{\partial f_1}\right\vert\left\vert\frac{\partial f_1}{\partial x}\right\vert\] <p>임을 알 수 있으므로,</p> \[\log p_\theta(x) = \log p_Z(f_\theta(x))+\sum_{i=1}^n \log \left\vert \frac{\partial f_i}{\partial f_{i-1}}\right\vert\] <h1 id="coupling-flow">Coupling Flow</h1> <p>이제 처음에 들었던 세 가지 의문점 중 첫 번째와 세 번째가 해결되었다. 그렇다면 마지막, 두 번째 의문점이 남는다.</p> <ul> <li>기존의 컨볼루션, linear layer, ReLU등으로 구성된 신경망은 역변환이 불가능한데, \(f\)를 어떻게 invertible하게 만들 수 있을까?</li> </ul> <p>일반적으로, 이를 위해서 사용하는 방법은 <strong>coupling flow</strong>이다. 이를 간단하게 설명하자면, 각 층의 입력 \(x\)를 \(x = (x^A\vert x^B)\)로 분할한 후 \(x^B\)만 변환하고 \(x^A\)는 그대로 남겨두는 것이다. 수식으로 이를 설명하자면 다음과 같다.</p> \[z = (z^A\vert z^B) = f(x) = f(x^A\vert x^B) = (x^A\vert \hat{f}(x^B\vert \psi_\theta (x^A)))\] <p>식을 보면, \(x^B\)를 변환하는 함수는 \(\hat{f}(x^B\vert \psi_\theta (x^A))\)로 표현된다는 것을 알 수 있다. 즉, \(x^A\)로부터 \(\psi_\theta (x^A)\)라는 값을 얻은 후, \(x^B\)를 변환할 때 이를 참고해서 사용한다는 것으로 해석하면 된다. 또, \(\hat{f}\)는 가역이라는 조건이 붙는다.</p> <p>이렇게 하면 \(z\)만 보고 \(x\)를 쉽게 얻어낼 수 있다! 먼저 \(z^A = x^A\)이므로 \(x^A\)는 바로 얻어낼 수 있다. \(x^B\)만 얻어내면 되는 것인데, 이는 다음의 과정으로 계산이 가능하다.</p> <ol> <li>먼저 \(\psi(x^A)=\psi(z^A)\)를 구한다.</li> <li>\(z^B = \hat{f}(x^B\vert\psi(x^A))\)이고, \(\hat{f}\)는 가역이며, \(\psi(x^A)\)를 알고 있으니 함수의 역을 취해서 \(x^B\)를 얻어낼 수 있다.</li> </ol> <p>즉, \(f\)는 가역 함수가 된다. 가역함수끼리 합성해도 가역함수가 되므로, 이러한 \(f\)를 앞서 설명한 것처럼 거듭해 쌓으면 더 강력한 표현력을 가진 flow를 얻을 수 있다. 한편, coupling flow의 Jacobian determinant \(\left\vert\frac{\partial f_\theta}{\partial x}\right\vert\)를 구하면 다음과 같다.</p> \[\left\vert\frac{\partial f_\theta}{\partial x}\right\vert = \left\vert \frac{\partial \hat{f}}{\partial x^B}(x^B\vert \psi_{\theta}(x^A))\right\vert\] <h2 id="additive-transformation-nice">Additive Transformation (NICE)</h2> <p>L. Dinh et al. (2014), “Nice: Non-linear independend components estimation”에서 사용한 방법이다. 단순히</p> \[z_{1:n/2} = x_{1:n/2}, z_{n/2:n} =x_{n/2:n} = x_{n/2:n }+t_\theta(x_{1:n/2})\] <p>로 정의하는 방식이다. 즉, 입력 데이터의 앞부분 절반은 변형 없이 그대로 내보내고, 나머지 절반은 앞부분으로부터 얻은 어떤 함수값을 더해주기만 하는 방식이다. 이 경우 inverse는</p> \[x_{1:n/2} = z_{1:n/2}, x_{n/2:n} =z_{n/2:n} = x_{n/2:n }-t_\theta(z_{1:n/2})\] <p>로 쉽게 계산할 수 있게 되고, Jacobian determinant는 \(\left\vert\frac{\partial f_\theta}{\partial x}\right\vert = 1\)이 된다.</p> <h2 id="affine-transformation-real-nvp">Affine Transformation (Real NVP)</h2> <p>L. Dinh et al. (2016), “Density estimation using real nvp”에서 사용된 방법이다. Real NVP에서 NVP는 non-volume-preserving의 약자로, 일종의 부피변화율의 의미를 갖는다고 한 Jacobian determinant가 NICE에서와는 다르게 1이 아니게 된다는 점에서 따온 말인 것으로 보인다. (논문을 읽지는 않아서 정확히는 모르겠다)</p> <p>Real NVP에서는 한발 더 나아가,</p> \[z_{1:n/2} = x_{1:n/2},\quad z_{n/2:n} =e^{s_\theta(x_{1:n/2})} \odot x_{n/2:n} +t_\theta(x_{1:n/2})\] <p>와 같이 계산이 이루어진다. 여기서 \(\odot\)은 elementwise multiplication을 의미한다. inverse는 (당연히)</p> \[x_{1:n/2}=z_{1:n/2}, \quad x_{n/2:n} = e^{-s_\theta(x_{1:n/2})}\odot (z_{n/2:n}-t_\theta(x_{1:n/2}))\] <p>로 계산할 수 있다. Jacobian determinant는 앞서 말했듯이 1이 아니게 되고, 게산을 해보면</p> \[\left\vert\frac{\partial f_\theta}{\partial x}\right\vert = \prod_{i}e^{s_\theta(x_{1:n/2})_i}=\text{exp}(\mathbb{1}_{n/2}^T s_{\theta}(x_{n/2:n}))\] <p>이 된다.</p> <h2 id="coupling-layer의-분할-방법">Coupling Layer의 분할 방법</h2> <p>위에서 \(x = (x^{A}, x^B)\)와 같이 분할할 때, 분할하는 방법을 계속 똑같이 둔다면 \(x^A\)에 해당하는 원소(픽셀)들은 계속 값이 바뀌지 않은 채로 놓이게 될 것이다. 따라서 일반적으로 flow model들에서는 각 계층마다 분할을 하는 방법을 계속 바꿔준다.</p> <p style="color:gray" align="center"> <img src="/assets/img/realnvp_masks.png" width="80%"> <br> coupling layer의 분할 방법. 좌: spatial checkerboard. 우: channelwise. 출처: L. Dinh et al. (2016) </p> <p>첫 번째 방법은 위의 왼쪽 그림처럼 checkerboar pattern으로 A와 B를 구분해주는 방법이다. 반면 두 번째 방법은 텐서를 reshape해준 후, 채널별로 A와 B를 구분해주는 방법이다. Real NVP의 경우 두 가지 방법을 교대로 3번씩 사용해주는 방식으로 충분한 표현력을 얻을 수 있도록 한다.</p> <h1 id="결론">결론</h1> <p>이제 글의 초반에 던졌던 세 가지 질문에 대한 답을 정리해보겠다.</p> <ul> <li>잠재벡터 \(Z\)는 왜 필요한 것일까? <ul> <li>각 데이터 \(X\)의 우도를 계산할 때, 뉴럴 네트워크가 곧바로 PDF를 출력하도록 하기에는 (1) normalization이 힘들고, (2) sampling이 어렵다는 문제점이 있다. flow에서는 이를 해결하기 위해서 주어진 데이터의 확률분포를 정규분포와 같은 간단한 분포로 매핑하는 함수 \(f_\theta\)를 정의하는데, 이것에 의해 입력 데이터 \(X_i\)는 잠재벡터 \(Z=f_\theta(X_i)\)로 매핑된다.</li> </ul> </li> <li>기존의 컨볼루션, linear layer, ReLU등으로 구성된 신경망은 역변환이 불가능한데, \(f\)를 어떻게 invertible하게 만들 수 있을까? <ul> <li>Coupling Flow를 사용해서 텐서를 두 부분으로 분할한 후, 절반은 그대로 두고 나머지 절반은 “첫번째 절반과의 correlation이 들어간” 가역 변환을 취해준다. NICE에서는 Additive Transformation을, Real NVP에서는 Affine Transformation을 사용한다.</li> </ul> </li> <li>인코더와 디코더를 거친 후 reconstruction loss를 구하면 되는 Autoencoder와 달리, flow model에서는 \(f^{-1}\circ f(X)=X\)가 된다. 그러면 트레이닝은 어떻게 시켜야 할까? <ul> <li>Maximum likelihood estimation을 트레이닝의 목표로 삼아, log likelihood을 최대화시킴으로서 트레이닝이 가능하다.</li> </ul> </li> </ul> </article><div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=localStorage.getItem("theme"),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"alshedivat/al-folio","data-repo-id":"MDEwOlJlcG9zaXRvcnk2MDAyNDM2NQ==","data-category":"Comments","data-category-id":"DIC_kwDOA5PmLc4CTBt6","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,a])=>giscusScript.setAttribute(t,a)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Seojune Lee. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>