<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>QSMNet 논문 리뷰 | Seojune Lee</title> <meta name="author" content="Seojune Lee"> <meta name="description" content="Quantitative susceptibility mapping using deep neural network: QSMnet"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700%7CRoboto+Slab:100,300,400,500,700%7CMaterial+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https:/vantaa89.github.io//blog/2022/QSM/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Seojune </span>Lee</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">QSMNet 논문 리뷰</h1> <p class="post-meta">June 24, 2022</p> <p class="post-tags"> <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a>   ·   <a href="/blog/tag/deep-learning"> <i class="fas fa-hashtag fa-sm"></i> deep-learning</a>   <a href="/blog/tag/medical-imaging"> <i class="fas fa-hashtag fa-sm"></i> medical-imaging</a>   <a href="/blog/tag/paper-review"> <i class="fas fa-hashtag fa-sm"></i> paper-review</a>   </p> </header> <article class="post-content"> <blockquote> <p><strong>요약</strong></p> <ul> <li>QSMnet을 제안</li> <li>single orientation만으로도 기존의 TKD, MEDI보다 좋은 성능, multiple orientation을 사용한 COSMOS와 comparable한 성능</li> </ul> </blockquote> <h1 id="abstract">Abstract</h1> <ul> <li>DNN은 CT, PET, MRI 등 medical image recon에서 좋은 성능을 보여옴.</li> <li>본 연구에서는 <strong>Quantitative Susceptibility Mapping</strong> (QSM)을 수행하는 DNN 기반 MRI reconstruction algorithm을 개발함 <ul> <li> <strong>Dipole Deconvolution</strong>을 수행 → MRI field map으로부터 magnetic susceptibility source를 복원하는 역할</li> </ul> </li> <li>기존 접근 방법은 multiple orientation data / regularization term들을 요구. ill-conditioned dipole deconvolution problem을 풀기 위해. <ul> <li>그러나 이들은 모두 data acquisition이 어렵거나, artifact로 인해 suffer</li> </ul> </li> <li><strong>QSMnet: single orientation data로부터 high quality susceptibility source map을 뽑아냄</strong></li> <li>U-net을 변형한 구조.</li> <li>Training에 대한 설명 <ul> <li> <strong>COSMOS QSM maps</strong>를 사용해 training (Gold standard)</li> <li>five subject로부터 five head orientation → model-based data augmentation → <strong>patch-wise network training</strong> </li> <li>7 datasets \(\times\) 5 head orientation = 35 images로 validataion(1 dataset) + test(6 datasets)</li> </ul> </li> <li>Performance에 대한 설명 <ul> <li>TKD, MEDI를 사용한 map들과의 비교 → 더 superior한 성능, COSMOS와 비교해서는 비슷한 성능</li> <li>multiple head orientation에서 TKD, MEDI보다 더 consistent한 성능을 보임</li> </ul> </li> <li>Preliminary application으로 세 명의 환자에 대해서 테스트 → MEDI를 사용한 이미지와 비슷한 lesion을 보여줌</li> </ul> <h1 id="introduction">Introduction</h1> <ul> <li> <strong>Magnetic susceptibility</strong>: 조직의 고유 성질로 외부 자기장에 얼마나 magnetize되는지를 나타냄. <ul> <li>최근 몇년간 MRI를 이용해 이를 정량적으로 측정하여 질병 진단하는 방법이 각광</li> </ul> </li> <li>MRI에서는 magnetic susceptibility source가 main B field를 perturb; source 바깥에서 resonance frequency의 variation을 유도 <ul> <li>point susceptibility source가 field 안에 있을 때, resonance frequency variation의 spatial pattern은 dipole shape과 유사.</li> <li>더욱 복잡한 susceptibility source distribution의 경우에는 <strong>source distribution과 dipole pattern의 convolution</strong>으로 나타낼 수 있음!</li> <li>field map의 경우 gradient-echo (GRE) sequence의 phase로 나타남</li> </ul> </li> <li>GRE의 phase image에서 <strong>spatial deconvolution</strong>을 하여 susceptiliby source distribution을 regenerate할 수 있음: Quantitative Susceptibility Mapping(QSM) <ul> <li>그러나 이는 ill-conditioned problem. dipole patern의 FT는 0을 포함 → 0 division problem <ol> <li> <strong>Truncated K-space division</strong>(TKD): k-space dipole pattern의 inversion을 truncate하여, zero-division으로 인한 발산을 막는 방법 → susceptibility map을 만들어내지만, <strong>streaking artifact</strong> </li> <li> <strong>Morphology Enabled Dipole Inversion</strong>(MEDI): recon map이 <strong><em>T2</em>-weighted magnitude image</strong>*와 비슷한 edge들을 갖도록 constrain →streaking artiface 감소. refined QSM /여전히 error 존재</li> <li><strong>Calculation of Susceptibility through Multiple Orientation Sampling (COSMOS)</strong></li> </ol> </li> <li>오래 찍어도 상관없으면, B0에 대한 여러 orientation으로 GRE data를 얻어 더 정밀하게.</li> <li>white matter에서의 susceptibility와 structural anisotropy를 제외하면 gold-standard로 취급</li> </ul> </li> <li>최근 medical imaging에서도 DL이 높은 성능을 보이고 있음 → 이 논문에서는 DNN을 dipole deconvolution 작업에 적용하여, high quality recon of QSM을 이뤄낼 수 있도록 함(<strong>QSMnet</strong>) <ul> <li> <strong>single orientation만 써서 COSMOS QSM의 퀄리티</strong>를 얻는걸 목표</li> </ul> </li> </ul> <h1 id="materials-and-methods">Materials and Methods</h1> <ul> <li>Data <ul> <li>Training/Testing: 12명의 건강한 지원자로부터 5 head orientation씩 → 60 scans (at 3 Tesla)</li> <li>Eval: 3명의 환자. microbleed(미세 뇌출혈) / multiple sclerosis(경화증) lesions / hemorrhage(출혈)</li> </ul> <p>→ 3D single-echo GRE scan을 얻음(axially). 건강한 지원자로부터는 5 orientations.</p> <ul> <li>k-space로부터 offline GRAPPA recon → magnitude / phase image를 뽑아냄 → <em>coil combination using sensitivities estimated using ESPIRiT</em> </li> <li>그 후 <em>V-SHARP</em>를 통해 background field 제거해 local field map을 얻어냄</li> <li>COSMOS를 통해 multiple head orientation data를 recon하는 과정 <ul> <li>각 orientation의 magnitude image를 rotation matrix에 넣어 unrotated head orientation으로 돌려놓음(<em>FSL’s FLIRT</em>)</li> <li>rotation matrix를 local field map에도 적용하여 <em>registration →</em> 이를 사용해 QSM 얻음</li> </ul> </li> <li>COSMOS QSM뿐만 아니라, TKD와 MEDI를 사용해서도 single orientation QSM을 얻어냄. 5 orientation의 phase image에 대해 각각 recon → 어느 정도 consistency를 기대</li> </ul> </li> <li>QSMnet 아키텍처 <ul> <li>Input: unregistered phase image</li> <li>Label: COSMOS QSM을 각 방향으로 rotate시킨 것 <ul> <li>multiple head orientation dataset으로부터 consistent한 deconvolution을 얻어내기 위해</li> </ul> <p align="center" style="color:gray"> <img src="/assets/posts/2022-07-20-QSM/Untitled1.png" width="60%" height="60%"> </p> </li> <li> <strong>Augmentation</strong>: <strong>COSMOS QSM map</strong>들을 B0 field에 대해 -30도 ~ 30도 <strong>회전시킨 후 dipole convolution</strong>해서 새로운 local field 데이터를 만들어 줌! <ul> <li>COSMOS를 우리는 ground truth로 생각하므로, 여기에 dipole convolution하면 새로운 local field data로 생각할 수 있음</li> </ul> </li> <li>\(64 \times 64 \times 64\) voxel로 이루어진 3D patch를 넣어 training. 이때 이웃한 patch끼리 약 66% overlap. 총 16800개의 patch</li> <li>U-net을 base structure로 사용. input과 output이 비슷한 structural contrast를 공유하기 때문에, <strong>U-net의 feature concatenation이 도움</strong>이 됨. <ul> <li>2D 대신 3D로 바꿈</li> <li>19 conv layer, 18 BatchNorm, 18 ReLU, 4 max-pooling, 4 transposed conv (deconv), 4 feature concat</li> </ul> <p align="center" style="color:gray"> <img src="/assets/posts/2022-07-20-QSM/Untitled2.png" width="60%" height="60%"> </p> </li> <li>Loss function: <strong>3가지를 디자인</strong>해 사용. <ul> <li> <p>각각 <strong>physical model consistency</strong>(Model loss), <strong>voxel-wise differnece</strong>(L1 loss), <strong>image edge preservation</strong> (Gradient loss)를 고려하기 위한 loss</p> <p>\(\mathrm{loss}_{\mathrm{Model}} = \vert\vert d * \chi - d * y\vert\vert_1\), \(\quad d\): dipole kernel / \(\chi, y\): 각각 output과 label</p> \[\mathrm{loss_{L1}}=\vert\vert\chi-y\vert\vert_1\] \[\mathrm{loss_{Gradient}}=\sum_{i=x, y, z}\lvert \vert\vert\nabla \chi\vert\vert_i-\vert\vert\nabla y\vert\vert_i\rvert\] </li> <li> <p>위 세 loss의 lin. combination으로 total sum.</p> </li> </ul> </li> </ul> </li> <li>Evaluation of QSM Algorithms <ul> <li>QSM map에 따른 퀄리티를 평가하기 위해서, 6명\(\times\)5 orientations = 30 scans를 3가지 recon method로 processing.</li> <li>metric: <strong>pSNR</strong>(peak SNR), <strong>NRMSE</strong>(normalized RMSE), <strong>HFEN</strong>(high-frequency error norm), <strong>SSIM</strong>(structural similarity index). COSMOS QSM map과 비교하는 데 사용</li> <li>t-test로 유의미한 차이가 있는지도 검정</li> <li>여러 head orientation에 대해서 QSM map의 consistency와 accuracy를 측정하기 위해서는 <strong><em>region of interest analysis</em></strong> 사용</li> <li>진료에서 실제 사용가능성에 대한 preliminary attempt로, 세 명의 환자에 대한 single-orientation data(train에 사용하지 않은)를 QSMnet을 사용해 recon → MEDI를 사용한 결과와 비교</li> </ul> </li> </ul> <h1 id="results">Results</h1> <ul> <li> <p>Three plane views(Fig. 2)</p> <p align="center" style="color:gray"> <img src="/assets/posts/2022-07-20-QSM/Untitled3.png" width="60%" height="60%"> </p> <ul> <li>TKD/MEDI는 coronal, sagittal view에서 streaking artifact가 나타남.</li> <li>QSMnet의 경우 noticeable artifact가 없었음. COSMOS와 거의 일치</li> <li>pSNR, NRMSE, HFEN, SSIM 등 모든 criteria에서 가장 높은 performance</li> </ul> </li> <li> <p>Five head orientations 비교(Fig. 3)</p> <p align="center" style="color:gray"> <img src="/assets/posts/2022-07-20-QSM/Untitled4.png" width="60%" height="60%"> </p> <ul> <li>QSMnet의 결과는 COSMOS와 아주 잘 일치</li> <li>head orientation에 따른 consistency로도 QSMnet이 가장 높은 성능</li> <li>붉은 화살표: TKD, MEDI는 streaking artifact, QSMnet은 X</li> <li>초록 화살표: internal capsule. TKD, MEDI는 orientation에 따라 contrast가 달라짐. QSMnet은 consistent한 결과.</li> </ul> </li> <li> <p>Fig. 3의 결과 확대(Fig. 4)</p> <p align="center" style="color:gray"> <img src="/assets/posts/2022-07-20-QSM/Untitled5.png" width="60%" height="60%"> </p> <ul> <li>파란색 동그라미: cortex의 cortical ribbons.</li> <li>QSMnet이 가장 detail을 잘 보존함 → cortical imaging에서의 활용 가능성 시사.</li> </ul> </li> <li>ROI에서의 susceptibility의 mean과 std를 head orientation에 따라 조사하면, QSMnet이 가장 tight한 error bar. → QSMnet의 superior accuracy를 의미</li> <li>속도에서 또한, QSMnet의 recon 속도가 MEDI 등에 비해서 빠름.</li> </ul> <h1 id="discussion-and-conclusion">Discussion and Conclusion</h1> <ul> <li>결과의 의의와 한계 <ul> <li>QSMnet을 제안하였고, 높은 성능을 보임. abnormality에 대한 적용도 가능할 것으로 생각되지만, 3명의 환자에 대해서만 테스트했기 때문에 결과의 응용에 한계가 있음</li> <li>NN은 표현력이 높지만, characterization이 어려움(not interpretable) → QSMnet의 결과는 주의해서 interpret해야 함.</li> <li>본 논문의 QSMnet에서는 dipole deconvolution function을 enforce하는 \(\mathrm{loss_{Model}}\) 텀이 사용됨. → image-to-image transformation(L1 loss가 enforce)보다는 physical model을 학습하도록 enforce하였을 것으로 생각 <ul> <li>세 가지 loss의 linear combination들에 대해 실험했을 때 여기서 사용된 조합이 가장 좋은 성능을 보였음 → proposed loss의 validity를 보여줌</li> </ul> </li> <li>augmentation: physical model의 training을 도왔을 것으로 생각</li> <li>결과에 대한 guarantee는 없지만, training data에 없는 뇌출혈 등의 특징도 잘 잡아냄 → 잘 훈련</li> </ul> </li> <li>훈련 과정에서 patch size를 바꾸어가며(32x32x32, 48x48x48, 64x64x64) 시험해본 결과 <ul> <li>32 x 32 x 32에서는 globus pallidus와 같은 커다란 structure가 잘 recon되지 않았음</li> <li>반면 patch size가 증가하면 training time이 크게 증가. 64x64x64는 좋은 compromise</li> </ul> </li> <li>multiple head orientation에 대해 QSM map을 얻은것을 보면 white matter가 consistent한 contrast를 보임 → QSMnet의 높은 reproducibility를 시사 <ul> <li>그러나 anisotropy와 micro-structure로 인해 이것이 정확한 결과라는 보장은 없음. 가능한 해석 중 하나는, QSMnet이 anisotropy를 supress한다는 것. COSMOS등의 isotropic susceptibility에 대해서만 훈련됐기 때문</li> <li>다른 해석: orientation 회전 자체가 작아서 anisotropy의 영향 자체가 작았기 때문이다</li> </ul> </li> <li>MEDI의 경우 regularization factor가 image quality에 큰 영향. 역시 regularization factor를 다르게 해서 테스트해본 결과, multiple head orientation에 대해 QSM result가 큰 variability를 보임</li> <li>QSMnet의 한계 <ul> <li>input resolution이 고정 → 낮은 resolution에 대해서는 interpolation이 필요. 반면 높은 resolution은 recon이 잘 작동하지 않음, 다시 training해야함</li> <li>이미지의 z-axis를 B0 field 방향으로 간주 → input data가 다른 방향인 경우 돌려줘야함</li> <li>이외의 acquisition parameter들에 대해서는 flexible(flip angle, TR, TE, …) <ul> <li><em>input이 local frequency map이기 때문</em></li> </ul> </li> </ul> </li> <li>resolution은 같지만 field of view 가 다른 경우 → 어차피 conv layer들이 sequential하게 처리하므로, 적용이 가능함</li> <li>본 연구에서는 background field가 잘 제거되었다고 가정하고 local field map에 대해 네트워크 적용. <ul> <li>background field가 잘 제거되지 않았다면 residual artifact 발생 가능 → 후속 연구는 background field removal과 dipole deconv step의 상호작용 규명 필요</li> <li>또는, 두 step을 모두 수행하는 combined network로</li> </ul> </li> <li>테스트한 사람이 적으므로, healthy/unhealthy volunteer에 대한 extensive testing이 필요함. 또한, network characteristics를 이해하려는 노력도 필요</li> </ul> </article><div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=localStorage.getItem("theme"),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"alshedivat/al-folio","data-repo-id":"MDEwOlJlcG9zaXRvcnk2MDAyNDM2NQ==","data-category":"Comments","data-category-id":"DIC_kwDOA5PmLc4CTBt6","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,a])=>giscusScript.setAttribute(t,a)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Seojune Lee. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>