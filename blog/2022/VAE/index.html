<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Variational Autoencoder | Seojune Lee</title> <meta name="author" content="Seojune Lee"> <meta name="description" content="Variational Autoencoder의 수학적 기반"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700%7CRoboto+Slab:100,300,400,500,700%7CMaterial+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https:/vantaa89.github.io//blog/2022/VAE/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Seojune </span>Lee</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Variational Autoencoder</h1> <p class="post-meta">November 18, 2022</p> <p class="post-tags"> <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a>   ·   <a href="/blog/tag/deep-learning"> <i class="fas fa-hashtag fa-sm"></i> deep-learning</a>   <a href="/blog/tag/math"> <i class="fas fa-hashtag fa-sm"></i> math</a>   <a href="/blog/tag/mathdnn"> <i class="fas fa-hashtag fa-sm"></i> MathDNN</a>   </p> </header> <article class="post-content"> <blockquote> <p>Erneset Ryu 교수님의 2022학년도 2학기 &lt;심층신경망의 수학적 기초&gt; 과목을 듣고 필자가 요약해 정리한 글입니다.</p> </blockquote> <h1 id="introduction">Introduction</h1> <p>Variational Autoencoder에 대해 설명하기 전에, 그 전단계인 Autoencoder에 대해 알아보고 넘어가자. <strong>Autoencoder</strong>는 이미지처럼 높은 차원의 입력 데이터를 잠재 공간(latent space)상의 저차원의 표현 벡터로 압축하는 <strong>인코더</strong>와, 다시 잠재 공간의 벡터를 원본으로 복원하는 것을 목표로 하는 <strong>디코더</strong>로 구성된 신경망이다. 인코더의 입력과 디코더의 출력의 차이(예를 들어 MSE)를 손실 함수로 설정함으로써, 인코더는 원본 이미지의 특성을 잘 살려서 벡터로 표현하는 방법을 학습하게 되고, 디코더는 표현 벡터만을 보고 원본 이미지에 가깝게 복원하는 방법을 학습하게 된다.</p> <p>여기서 디코더가 <strong>표현 벡터만을 보고 원래의 이미지를 복원</strong>해낸다는 점에 주목하자. 즉, 표현 벡터에는 원래 이미지의 중요한 정보들이 다 담겨있다는 것이다. 즉, 표현벡터는 원본 이미지에 담긴 특성(feature)들을 뽑아 저장해놓은 차원 축소의 역할을 한다고도 볼 수 있을 것이다. 실제로 VAE를 데이터의 차원을 축소하는 데 사용하는 경우가 많다.</p> <p align="center" style="color:gray"> <img src="/assets/posts/2022-11-19-VAE/image.png" width="80%" height="80%"> <br> VAE의 기본 구조. Autoencoder의 경우에도 같은 형태를 가진다. </p> <p>Variational Autoencoder는 Autoencoder에 확률적인 개념을 더해 개선한 것이다. 이 글에서는 VAE가 왜 타당한 모델인지, 그 motivation은 어디에서 나왔는지를 수학적으로 설명한 부분들을 정리해보려고 한다.</p> <h1 id="key-idea-of-vae">Key Idea of VAE</h1> <p>Variational Autoencoder는 크게 latent vector \(Z\) 가 주어졌을 때, 이미지의 확률분포를 나타내는 <strong>인코더</strong> \(q_\phi(z\vert x)\)와, 이미지 \(x\) 가 주어졌을 때 latent vector \(Z\)의 분포를 설명하는 <strong>디코더</strong> \(p_\theta(x\vert z )\)의 두 부분으로 구성된다. Autoencoder를 이해했다면 왜 저 두 함수가 각각 인코더와 디코더로 불리는지 쉽게 이해할 수 있겠지만 우선은 ‘인코더, 디코더’라는 명칭에 대해서는 넘어가기로 하자. 여기에서는 왜 저 두 함수가 필요한지를 조금 다른 motivation을 사용해 설명할 것이다.</p> <h2 id="목표-maximum-likelihood-estimation">목표: Maximum Likelihood Estimation</h2> <p>먼저, \(N\)개의 이미지(예를 들어서 \(N\)장의 고양이 사진) \(X_1, X_2, \cdots, X_N\) 가 주어져 있다고 생각하자. 우리의 목표는 이러한 고차원의 이미지들의 기저에 있는, underlying structure를 이해하는 것이다. 다르게 말하자면, \(N\)장의 고양이 사진들은 “고양이 사진의 확률분포”에서 \(N\) 번 샘플링된 것이라고 가정할 수 있으며, 그 확률밀도함수 \(p_X(x)\) 를 알아내는 것을 목표로 삼을 수 있을 것이다.</p> <p>이는 늘 그렇듯이 <strong>최우도추정(maximum likelihood estimation, MLE)</strong> 을 통해서 할 수 있다. IID로 \(p_X(x)\)에서 샘플링을 했을 때, 저 N개의 이미지가 모두 나올 확률(정확히는 likelihood)은 \(p_X(X_1)p_X(X_2)\cdots p_X(X_n)\) 가 되므로 이를 최대화하면 되는 것이다. 곱으로 이루어진 식은 다루기 어려우므로 로그를 씌우면 우리의 목표는 \(\text{maximize}_{p} \sum_{i=1}^N\log p(X_i)\) 가 된다. \(p\)라는 함수가 \(\theta\)로 매개화되는 함수라고 하면, 다시</p> \[\text{maximize}_{\theta \in \Theta} \sum_{i=1}^N\log p_\theta(X_i)\] <p>로 쓸 수 있을 것이다. 이때 \(p_\theta\) 는 신경망으로 구현되며, \(\theta\) 는 그 가중치가 될 것이다.</p> <p>그런데 autoencoder에서 설명했듯이 이미지 \(X\) 에는 그 기저에 \(Z\) 라는, 이미지의 특성을 설명하는 변수가 있어 \(Z\) 만 알면 \(X\) 가 거의 결정된다고 할 수 있다. 따라서 전확률공식과 조건부확률을 사용해서</p> \[p_\theta(X) = \int p_\theta(X|z)p_Z(z) dz = \mathbb{E}_{Z \sim p_Z}[p_\theta(X|Z)]\] <p>로 쓸 수 있다. 그러면 다시 우리의 목표는</p> \[\text{maximize}_{\theta \in \Theta} \sum_{i=1}^N \log \mathbb{E}_{Z \sim p_Z}[p_\theta(X_i|Z)]\] <p>로 바뀌게 된다. \(p_Z\) 는 여기서 알려져있는 함수로, 일반적으로 (다변수) 표준정규분포를 사용한다.</p> <h2 id="importance-sampling">Importance Sampling</h2> <p>이제 위의 식을 어떻게 최대화할지를 생각해봐야 할 것이다. 여기서 문제점은 식에 기댓값이 끼어있다는 것이다. \(Z\) 가 이산확률변수라면 그냥</p> \[\mathbb{E}_{Z \sim p_Z}[p_\theta(X|Z)]=\sum_i p_Z(z_i)p_\theta(X|z_i)\] <p>처럼 다 더해버리면 된다. 하지만 \(Z\) 는 연속적인 분포를 가지기 때문에 \(\int p_\theta(X\vert z)p_Z(z) dz\) 를 계산해야 하며, 이는 굉장히 어렵다. 이 때문에 \(Z_i\) 를 샘플링해서 \(\mathbb{E}\) 의 근사값을 구해 사용하게 된다.</p> \[\sum_{i=1}^N \log \mathbb{E}_{Z \sim p_Z} [p_\theta(X_i|Z)] \approx \sum_{i=1}^N \log p_\theta(X_i|Z_i)\quad\quad Z_i \sim p_Z\] <p>사실 위의 식은 각 이미지 \(X_i\) 에 대해서, 그 이미지를 만들어낸(만들어냈을 것이라고 생각되는) latent vector \(Z\) 를 한개씩만 샘플링하여 구하기 때문에 매우 부정확한 근사이다. 따라서 우리는 <strong>Importance Sampling</strong> 이라는 개념을 도입해서 이를 해결한다.</p> <h3 id="importance-sampling의-개념">Importance Sampling의 개념</h3> <p>\(X\) 가 \(f(x)\) 라는 확률밀도함수를 가질 때 \(\mathbb{E}_{X\sim f}[\phi(X)]\) 를 구해야 하는 상황을 생각해보자. 그런데 적분을 실제로 해서 이를 구하는 것이 어려운 상황이 많기 때문에 위와 같이 많은 경우 \(X\) 를 적당히 샘플링해서</p> \[\mathbb{E}_{X\sim f}[\phi(X)]\approx \frac{1}{N}\sum_{i=1}^k \phi(X_i)\] <p>과 같이 근사해서 사용한다. 이를 <strong>Monte Carlo Estimation</strong> 이라고 한다. 큰 수의 법칙에 의해, \(N\)이 커지면 커질수록 우변은 실제 기대값과 매우 유사한 값을 가지게 될 것이다.</p> <p>하지만 위와 같은 근사는 때때로 분산이 너무 커서 실제로는 사용하기 힘들거나, \(N\)이 아주 커야 정확해질 때가 많다. 따라서 <strong>Importance Sampling</strong> 이라는 개념을 사용해서 분산을 줄이게 된다. Importance Sampling의 핵심은 X의 분포 함수 \(f\)를 다른 “좋은” 함수 \(g\)로 바꾸는 것이다. 이를 위해 아래와 같은 테크닉을 사용한다.</p> \[\mathbb{E}_{X\sim f}[\phi(X)] = \int \phi(x) f(x) dx = \int \frac{\phi(x)f(x)}{g(x)} g(x) dx\] <p>이는 기대값을 사용해 아래와 같이 쓸 수 있다.</p> \[\mathbb{E}_{X\sim f}[\phi(X)] = \mathbb{E}_{X \sim g}\left[\frac{\phi(X)f(X)}{g(X)} \right]\] <p>앞서 말했듯이, \(X\) 가 따르는 분포(확률밀도함수)가 \(f\) 에서 \(g\)로 바뀐 것을 볼 수 있을 것이다. \(g\)를 적절하게 선택하면 원래보다 더 정확한(variance가 낮은) 추정을 할 수 있게 된다.</p> <p>그러면 \(g\)는 어떻게 선택해야 할까? 이상적으로는</p> \[g(X) = \frac{\phi(X)f(X)}{I} \quad(I = \int \phi(x) f(x) dx)\] <p>로 놓으면 분산이 0으로 최소가 된다. 그런데 \(I\)는 우리가 알고 있는 값이 아니므로(\(I = \mathbb{E}_{X\sim f}[\phi(X)]\)이므로 \(I\)를 알고 있다면 애초에 이 짓을 할 필요가 없다) 이러한 함수는 우리가 사용할 수 없다.</p> <p>따라서 \(g\)가 이상적인 함수 \(\frac{\phi(X)f(X)}{I}\)와 갖는 거리를 구해서, 이것이 최소화되도록 함으로써 어느 정도 좋은 \(g\) 를 구할 수 있다. \(g\) 는 \(\theta\) 로 parametrize된 신경망으로 구성되어 있다고 가정하자. KL-Divergence를 사용하면,</p> \[D_{KL} (g_\theta||\phi f/I) = \mathbb{E}_{x\sim g_\theta}\left[{\log\left(\frac{Ig_\theta (X)}{\phi(X)f(X)}\right)}\right]\\ = \mathbb{E}_{x\sim g_\theta}\left[{\log\left(\frac{g_\theta (X)}{\phi(X)f(X)}\right)}\right] + \log I\] <p>이며, \(\log I\)는 \(\theta\)에 대해서는 상수이므로</p> \[\mathbb{E}_{x\sim g_\theta}\left[{\log\left(\frac{g_\theta (X)}{\phi(X)f(X)}\right)}\right]\] <p>를 SGD를 사용해서 최소화하면 된다. 이렇게 구한 \(g_\theta\)를 사용하여 Importance Sampling을 하면 \(I\)를 비교적 낮은 variance로 추정할 수 있다.</p> <h3 id="z를-importance-sampling하자">Z를 importance sampling하자</h3> <p>이제 원래의 문제로 돌아와서, 이미지 \(X_i\)에 대해</p> \[p_\theta(X_i) =\mathbb{E}_{Z \sim p_Z} [p_\theta(X_i|Z)]\] <p>를 \(Z_i\sim q_i(z)\)를 사용한 importance sampling을 통해 근사해 보자.</p> \[\mathbb{E}_{Z \sim p_Z} [p_\theta(X_i|Z)] \approx p_\theta(X_i|Z_i)\frac{p_Z(Z_i)}{q_i(Z_i)}\quad \quad Z_i \sim q_i(z)\] <p>이때 \(q_i\)는 앞서 설명한 것과 마찬가지로</p> \[q_i^*(z) = \frac{p_\theta(X_i|z)p_Z(z)}{p_\theta(X_i)} = p_\theta(z|X_i)\] <p>일 때 최대가 될 것이다. 그런데 베이즈 정리에 의해서, 이는 \(p_\theta(z\vert X_i)\)와 같다. 물론 이는 정확하게 계산이 불가능하며(\(p_\theta(X_i)\)를 모르니), KL-Divergence 를 통해 \(q_i^*\)와 최대한 비슷한 \(q_i\)를 찾아야 한다.</p> \[D_{KL}(q_i(\cdot) || q_i^*(\cdot))\] \[= D_{KL}(q_i(\cdot) || p_\theta(\cdot|X_i))\] \[= \mathbb{E}_{Z\sim q_i}\log\left(\frac{q_i(Z)}{p_\theta(Z|X_i)} \right)\] \[=\mathbb{E}_{Z\sim q_i}\log\left(\frac{q_i(Z)}{p_\theta(X_i|Z)p_Z(Z)/p_\theta(X_i)} \right)\] \[=\mathbb{E}_{Z\sim q_i} [\log(q_i(Z)) - \log(p_\theta(X_i|Z))-\log p_Z(Z) ]+ \log p_\theta(X_i)\] <p>마지막 줄에서, \(\log p_{\theta}(X_i)\)는 \(Z\)와 무관한 항이므로 최소화할 때 무시해줘도 된다. 그러면 \(q_i(Z), p_{\theta}(X_i\vert Z), p_Z(Z)\)는 모두 우리가 계산할 수 있는 항들이므로 \(q_i\)를 잘 조절함으로써 최소화가 가능하다.</p> <h3 id="amortized-inference">Amortized Inference</h3> <p>그런데 위에서 \(q_i\)를 보면 index \(i\)가 붙어있는 것을 알 수 있다. 즉, 각 데이터(이미지) \(X_i\)에 대해서 개별적으로 최적화 문제를 풀고 있는 것이다. 당연히 이는 계산이 매우 많이 걸릴 것이다.</p> <p>따라서 우리는 함수 \(q\)를 신경망으로 구성하고, 그 가중치 \(\phi\)로 parametrize하여 \(q_\phi\)로 만든다. 그리고</p> \[\sum_{i=1}^ND_{KL}(q_\phi(\cdot|X_i) || q_i^*(\cdot))\] <p>를 loss 함수로 삼아서 SGD를 사용해 최소화한다. 이렇게 하면, \(q_\phi\)는 넣어주는 이미지 \(X_i\)에 따라서 다른 분포 \(q_i(z)\)를 나타내게 된다. 즉 하나의 함수 \(q_\phi(z\vert X)\)만으로 \(N\)개의 계산과정을 대신할 수 있는 것이다. 즉,</p> \[q_\phi(z|X_i) = q_i(z) \approx q_i^*(z) = p_\theta(z|X_i)\quad \text{for all } i = 1, \cdots, N\] <p>가 되는 것이다. 이 \(q_\phi\)가 바로 인코더가 된다.</p> <h1 id="encoder와-decoder의-최적화">Encoder와 Decoder의 최적화</h1> <p>이제 인코더 \(q_\phi\)와 \(p_\theta\)를 최적화하면 된다. 먼저 인코더의 목표는 앞에서 설명한 것처럼 각 이미지 \(X_i\)에 대해 importance sampling을 하는 최적의 함수 \(q_i^*\)를 amortized inference로 근사하는 것이 된다.</p> \[\text{minimize}_{\phi\in\Phi}\sum_{i=1}^ND_{KL}(q_\phi(\cdot|X_i) || q_i^*(\cdot))\] \[= \text{maximize}_{\phi\in\Phi} \sum_{i=1}^N \mathbb{E}_{Z\sim q_\phi(z|X_i)}\log\left(\frac{q_i(Z)}{p_\theta(Z|X_i)} \right)\] \[= \text{maximize}_{\phi\in\Phi}\mathbb{E}_{Z\sim q_\phi(z|X_i)} \left[\log\left(\frac{p_\theta(X_i|Z)p_Z(Z)}{q_\phi(Z|X_i)}\right) \right]\] \[= \text{maximize}_{\phi\in\Phi}\sum_{i=1}^N \mathbb{E}_{Z\sim q_\phi(z|X_i)}[\log p_\theta(X_i|Z)-D_{KL}(q_\phi(\cdot|X_i)||p_Z(\cdot))]\] <p>디코더의 목표는 (당연히) Maximum Likelihood Estimation을 수행하는 것이다.</p> \[\text{maximize}_{\theta\in\Theta}\sum_{i=1}^N \log p_\theta(X_i)\] \[= \text{maximize}_{\theta\in\Theta} \log\mathbb{E}_{Z\sim p_Z}\left[p_\theta(X_i|Z)\right]\] \[\approx\text{maximize}_{\theta \in\Theta} \sum_{i=1}^N \log\left(\frac{p_\theta(X_i|Z)p_Z(Z)}{q_\phi(Z|X_i)} \right)\quad (Z\sim q_{\phi}(z|X_i))\] \[\approx\text{maximize}_{\theta \in\Theta} \sum_{i=1}^N \mathbb{E}_{Z_\sim q_{\phi}(z|X_i)}\left[\log\left(\frac{p_\theta(X_i|Z)p_Z(Z)}{q_\phi(Z|X_i)} \right)\right]\] \[= \text{maximize}_{\theta \in\Theta} \sum_{i=1}^N \mathbb{E}_{Z_\sim q_{\phi}(z|X_i)} \left[\log p_\theta(X_i|Z)\right] - D_{KL}(q_\phi (\cdot|X_i)||p_Z(\cdot))\] <p>우연히도 두 식의 형태가 똑같은 것을 알 수 있다! 따라서 위 식을 최대화하는 \(\theta\)와 \(\phi\)를 찾으면 된다. 즉,</p> \[\text{maximize}_{\theta \in\Theta, \phi \in \Phi} \sum_{i=1}^N \mathbb{E}_{Z_\sim q_{\phi}(z|X_i)} \left[\log p_\theta(X_i|Z)\right] - D_{KL}(q_\phi (\cdot|X_i)||p_Z(\cdot))\] <p>를 찾는 것이 VAE의 training objective가 된다.</p> <h2 id="standard-vae-setup">Standard VAE setup</h2> <p>이제 표준적인 setup의 VAE에서 일반적으로 사용하는</p> \[p_Z = N(0, I),\quad q_\phi(z\vert x) = N(\mu_\phi(x), \Sigma_\phi(x)), \quad p_\theta(x\vert z) = N(f_\theta(x), \sigma^2 I)\] <p>의 확률분포들을 대입해주자. 이때 \(\Sigma_\phi\)는 대각행렬으로 한다. 그러면,</p> <p>다변수 정규분포의 확률밀도함수</p> \[p_X(x) = \frac{1}{(2\pi)^{k/2}} e^{-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)}\] <p>에 의해서(\(X \sim N(\mu, \Sigma)\), \(X\) 는 \(k\) 차원), 위의 training objective는</p> \[\text{maximize}_{\theta \in\Theta, \phi \in \Phi} \sum_{i=1}^N \mathbb{E}_{Z_\sim q_{\phi}(z|X_i)} \left[-\frac{1}{2\sigma^2} \vert\vert X_i - f_\theta(Z)\vert\vert^2\right] - D_{KL}(q_\phi (\cdot|X_i)||N(0, I))\] \[= \text{minimize}_{\theta \in\Theta, \phi \in \Phi} \sum_{i=1}^N \mathbb{E}_{Z_\sim q_{\phi}(z|X_i)} \left[\frac{1}{2\sigma^2} \vert\vert X_i - f_\theta(Z)\vert\vert^2\right] + D_{KL}(q_\phi (\cdot|X_i)||N(0, I))\] \[= \text{minimize}_{\theta \in\Theta, \phi \in \Phi} \sum_{i=1}^N \mathbb{E}_{Z_\sim q_{\phi}(z|X_i)} \left[\frac{1}{2\sigma^2} \vert\vert X_i - f_\theta(Z)\vert\vert^2\right] + \frac{1}{2}\left\{\text{tr}(\Sigma_\phi(X_i))+ \vert\vert \mu_\phi(X_i) \vert\vert^2 - d- \log {\mathrm{det}\Sigma_\phi(X_i)}\right\}\] \[= \text{minimize}_{\theta \in\Theta, \phi \in \Phi} \sum_{i=1}^N \mathbb{E}_{Z_\sim q_{\phi}(z|X_i)} \left[\frac{1}{\sigma^2} \vert\vert X_i - f_\theta(Z)\vert\vert^2\right] + \text{tr}(\Sigma_\phi(X_i))+ \vert\vert \mu_\phi(X_i) \vert\vert^2 - \log {\mathrm{det}\Sigma_\phi(X_i)}\] <p>로 바뀌게 된다. <br> 트레이닝을 위해서는 위의 식을 \(\theta\)와 \(\phi\)에 대해 편미분하여 기울기를 구하고, 이를 통해 Stochastic Gradient Descent를 진행해야 하는데, 기댓값에 \(\theta\)와 \(\phi\)가 아랫첨자로 붙어있으니 기울기를 쉽게 구할수 없다. 위와 같이 기댓값의 기울기를 구해야 할 때 사용할 수 있는 방법으로는 <strong>reparametrization trick</strong>과 <strong>log-derivative trick</strong>(a.k.a. REINFORCE)이 있다. 여기서는 reparametrization trick을 사용해서 기울기를 구해본다.</p> <h2 id="reparametrization-trick">Reparametrization Trick</h2> <p>Reparametrization Trick에서는 \(Z_i\sim N(\mu_{\phi}(X_i), \Sigma_\phi(X_i))\)를 표준정규분포를 따르는 다른 확률변수 \(\epsilon_i \sim N(0, 1)\)를 사용해</p> \[Z_i = \mu_\phi (X_i) + \Sigma_{\phi}^{1/2}(X_i) \epsilon_i\] <p>와 같이 매개화한다. 여기서 \(\Sigma_\phi\) 는 대각행렬이며, 모든 성분이 0 이상이므로 각 성분에 제곱근을 취함으로써 \(\Sigma_\phi^{1/2}\)를 쉽게 구할 수 있다. 대입을 마치면 optimization objective는</p> \[\text{minimize}_{\theta \in\Theta, \phi \in \Phi} \sum_{i=1}^N \mathbb{E}_{\epsilon \sim N(0, 1)} \left[\frac{1}{\sigma^2} \vert\vert X_i - f_\theta(\mu_\phi(X_i) + \Sigma_\phi^{1/2}(X_i)\epsilon )\vert\vert^2\right] + \text{tr}(\Sigma_\phi(X_i))+ \vert\vert \mu_\phi(X_i) \vert\vert^2 - \log {\mathrm{det}\Sigma_\phi(X_i)}\] <p>로 바뀐다. 이제 기댓값이 \(\theta, \phi\)와는 무관한 식으로 바뀌었으므로 기댓값 안의 항을 미분하여 기울기를 쉽게 구하여 SGD를 시행할 수 있다.</p> <p>한편, 위의 식을 보면 loss가 크게</p> \[\frac{1}{\sigma^2}\mathbb{E}_{\epsilon \sim N(0, 1)} \left[\vert\vert X_i -f_\theta(\mu_\phi(X_i) + \Sigma_\phi^{1/2}(X_i)\epsilon)\vert\vert^2\right]\] <p>과</p> \[2D_{KL}(q_\phi(\cdot|X_i)\vert\vert p_z(\cdot)) = \text{tr}(\Sigma_\phi(X_i))+ \vert\vert \mu_\phi(X_i) \vert\vert^2 - \log {\mathrm{det}\Sigma_\phi(X_i)}\] <p>로 나눠지는 것을 알 수 있다. 전자를 자세히 보면 원래의 입력 이미지 \(X_i\)와, encoder와 decoder를 거쳐서 나온 reconstruct된 이미지 \(f_\theta(\mu_\phi(X_i) + \Sigma_\phi^{1/2}(X_i)\epsilon)\) 사이의 차이를 구하는 것이므로, <strong>reconstruction term</strong>라고 부를 수 있을 것이다. 후자의 경우 \(X_i\)를 latent space상으로 보내는 매핑이 일반적인 \(Z\)의 분포 \(N(0, I)\)과 너무 멀어지지 않도록 조절하는 역할을 하며, <strong>regularization term</strong>이라 명명될 수 있을 것이다.</p> <p>식을 보면 decoder의 출력에 더해주는 noise의 크기를 결정하는 \(\sigma\)가 두 term 사이의 가중치를 조절하는 hyperparameter의 역할을 하는 것을 알 수 있다.</p> </article><div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=localStorage.getItem("theme"),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"alshedivat/al-folio","data-repo-id":"MDEwOlJlcG9zaXRvcnk2MDAyNDM2NQ==","data-category":"Comments","data-category-id":"DIC_kwDOA5PmLc4CTBt6","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,a])=>giscusScript.setAttribute(t,a)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Seojune Lee. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>